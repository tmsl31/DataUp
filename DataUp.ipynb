{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataUp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proyecto del curso \"Taller de Proyecto\". Análisis de entrevistas utilizando procesamiento de voz y técnicas de análisis de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import speech_recognition as sr #Speech Recognition\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "#Pre procesamiento\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "#nltk.download('wordnet') \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Procesamiento de Voz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- Análisis del Texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.- Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"Un edificio gris, achaparrado, de sólo treinta y cuatro plantas. Encima de la entrada principal las palabras: Centro de Incubacion y Condicionamiento de la Central de Londres, y, en un escudo, la divisa del Estado Mundial: Comunidad, Identidad, Estabilidad. Dentro, la enorme sala de la planta baja se hallaba orientada hacia el Norte. Fría a pesar del verano que reinaba en el exterior y del calor tropical de la sala, una luz cruda se filtraba a través de las ventanas buscando ávidamente algún cuerpo amortajado o alguna figura pálida, producto de las disecciones académicas; sin encontrar más que el cristal, el níquel y la brillante porcelana de un laboratorio. Lo invernal respondía a lo invernal. Las batas de los trabajadores eran blancas, y éstos llevaban las manos enfundadas en guantes de goma de un color pálido, como de cadáver. La luz era helada, muerta, fantasmal. Sólo de los amarillos cilindros de los microscopios se lograba arrancar cierta calidad de vida, deslizándose a lo largo de los tubos y formando una dilatada procesión de trazos luminosos que seguían la larga perspectiva de las mesas de trabajo.\"\n",
    "pandasText = pd.DataFrame([texto],columns = ['Texto'], index = [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1.- Eliminacion de stopwords y ruido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing stopwords: Stop words include the large number of prepositions, pronouns, conjunctions etc in sentences. These words need to be removed before we analyse the text, so that the frequently used words are mainly the words relevant to the context and not common words used in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcesamiento(textoPandas,stopWords, deleteStopWords = 1, lemanizacion = 0):\n",
    "    #Funcion que realiza el preProcesamiento del texto.\n",
    "    \n",
    "    #Convertir a Pandas.\n",
    "    text = textoPandas['Texto'][1]\n",
    "    #Pasar a minusculas.\n",
    "    text = text.lower()\n",
    "    #Convertir a vector de palabras.\n",
    "    text = text.split()\n",
    "    #Eliminar stopWords\n",
    "    text = [word for word in text if not word in stopWords]\n",
    "    #Decidir si lemanizar o no\n",
    "    if lemanizar == 1:\n",
    "        lem = WordNEtLemmatizer()\n",
    "        text = [lem.lemmatize(word) for word in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista de stop words en espanol. Util para elminaras del texto original.\n",
    "stopWords = set(stopwords.words(\"spanish\"))\n",
    "#Obtencion de txto desde pandas.\n",
    "text = pandasText['Texto'][1]\n",
    "#Procesamiento\n",
    "#Paso a minusculas\n",
    "text = text.lower()\n",
    "#Convertir a lista desde string\n",
    "text = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['un', 'edificio', 'gris,', 'achaparrado,', 'de', 'sólo', 'treinta', 'y', 'cuatro', 'plantas.', 'encima', 'de', 'la', 'entrada', 'principal', 'las', 'palabras:', 'centro', 'de', 'incubacion', 'y', 'condicionamiento', 'de', 'la', 'central', 'de', 'londres,', 'y,', 'en', 'un', 'escudo,', 'la', 'divisa', 'del', 'estado', 'mundial:', 'comunidad,', 'identidad,', 'estabilidad.', 'dentro,', 'la', 'enorme', 'sala', 'de', 'la', 'planta', 'baja', 'se', 'hallaba', 'orientada', 'hacia', 'el', 'norte.', 'fría', 'a', 'pesar', 'del', 'verano', 'que', 'reinaba', 'en', 'el', 'exterior', 'y', 'del', 'calor', 'tropical', 'de', 'la', 'sala,', 'una', 'luz', 'cruda', 'se', 'filtraba', 'a', 'través', 'de', 'las', 'ventanas', 'buscando', 'ávidamente', 'algún', 'cuerpo', 'amortajado', 'o', 'alguna', 'figura', 'pálida,', 'producto', 'de', 'las', 'disecciones', 'académicas;', 'sin', 'encontrar', 'más', 'que', 'el', 'cristal,', 'el', 'níquel', 'y', 'la', 'brillante', 'porcelana', 'de', 'un', 'laboratorio.', 'lo', 'invernal', 'respondía', 'a', 'lo', 'invernal.', 'las', 'batas', 'de', 'los', 'trabajadores', 'eran', 'blancas,', 'y', 'éstos', 'llevaban', 'las', 'manos', 'enfundadas', 'en', 'guantes', 'de', 'goma', 'de', 'un', 'color', 'pálido,', 'como', 'de', 'cadáver.', 'la', 'luz', 'era', 'helada,', 'muerta,', 'fantasmal.', 'sólo', 'de', 'los', 'amarillos', 'cilindros', 'de', 'los', 'microscopios', 'se', 'lograba', 'arrancar', 'cierta', 'calidad', 'de', 'vida,', 'deslizándose', 'a', 'lo', 'largo', 'de', 'los', 'tubos', 'y', 'formando', 'una', 'dilatada', 'procesión', 'de', 'trazos', 'luminosos', 'que', 'seguían', 'la', 'larga', 'perspectiva', 'de', 'las', 'mesas', 'de', 'trabajo.']\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_df=1,stop_words=stopWords, max_features=10000, ngram_range=(1,3))\n",
    "X = cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 178)\t1\n",
      "  (0, 256)\t1\n",
      "  (0, 165)\t1\n",
      "  (0, 292)\t1\n",
      "  (0, 271)\t1\n",
      "  (0, 189)\t1\n",
      "  (0, 318)\t1\n",
      "  (0, 247)\t1\n",
      "  (0, 70)\t1\n",
      "  (0, 110)\t1\n",
      "  (0, 321)\t1\n",
      "  (0, 184)\t1\n",
      "  (0, 163)\t1\n",
      "  (0, 89)\t1\n",
      "  (0, 324)\t1\n",
      "  (0, 32)\t1\n",
      "  (0, 29)\t1\n",
      "  (0, 283)\t1\n",
      "  (0, 148)\t1\n",
      "  (0, 197)\t1\n",
      "  (0, 172)\t1\n",
      "  (0, 26)\t1\n",
      "  (0, 203)\t1\n",
      "  (0, 176)\t1\n",
      "  (0, 300)\t1\n",
      "  :\t:\n",
      "  (0, 93)\t1\n",
      "  (0, 132)\t1\n",
      "  (0, 41)\t1\n",
      "  (0, 209)\t1\n",
      "  (0, 96)\t1\n",
      "  (0, 77)\t3\n",
      "  (0, 74)\t1\n",
      "  (0, 287)\t1\n",
      "  (0, 158)\t1\n",
      "  (0, 50)\t1\n",
      "  (0, 44)\t1\n",
      "  (0, 135)\t1\n",
      "  (0, 47)\t1\n",
      "  (0, 233)\t1\n",
      "  (0, 166)\t10\n",
      "  (0, 251)\t1\n",
      "  (0, 227)\t1\n",
      "  (0, 90)\t1\n",
      "  (0, 239)\t1\n",
      "  (0, 62)\t1\n",
      "  (0, 307)\t1\n",
      "  (0, 298)\t2\n",
      "  (0, 21)\t1\n",
      "  (0, 117)\t1\n",
      "  (0, 65)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['difici',\n",
       " 'gris',\n",
       " 'chprrd',\n",
       " 'sól',\n",
       " 'trint',\n",
       " 'cutr',\n",
       " 'plnts',\n",
       " 'encim',\n",
       " 'ntrd',\n",
       " 'principl']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cv.vocabulary_.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
