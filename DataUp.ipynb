{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataUp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proyecto del curso \"Taller de Proyecto\". Análisis de entrevistas utilizando procesamiento de voz y técnicas de análisis de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "#Genericas.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "#Reconocimiento de voz.\n",
    "import speech_recognition as sr\n",
    "import pyaudio\n",
    "#Procesamiento de texto.\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Procesamiento de Voz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Captura \n",
    "def capturaAudio(tiempoEspera = 5):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        #Ajuste a piso de ruido.\n",
    "        r.adjust_for_ambient_noise(source)\n",
    "        print('Comience el audio')\n",
    "        #Iniciar escucha.\n",
    "        audio = r.listen(source, timeout = tiempoEspera)\n",
    "        try:\n",
    "            # for testing purposes, we're just using the default API key\n",
    "            # to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n",
    "            # instead of `r.recognize_google(audio)`\n",
    "            texto = r.recognize_google(audio,language=\"es-CL\")\n",
    "            print(\"Google Speech Recognition thinks you said \" + texto)\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Google Speech Recognition could not understand audio\")\n",
    "        except sr.RequestError as e:\n",
    "            print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "        print ('Termino de audio')\n",
    "        \n",
    "        return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comience el audio\n",
      "Google Speech Recognition thinks you said dulzura dulce dulce dulcísimo dulce dulce dulce dulce amargo amargo amargo amargo amargo\n",
      "Termino de audio\n"
     ]
    }
   ],
   "source": [
    "audioPrueba = capturaAudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dulzura dulce dulce dulcísimo dulce dulce dulce dulce amargo amargo amargo amargo amargo'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audioPrueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- Análisis del Texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.- Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"Un edificio gris, achaparrado, de sólo treinta y 4 plantas. Encima de la entrada principal las palabras: Centro de Incubacion y Condicionamiento de la Central de Londres, y, en un escudo, la divisa del Estado Mundial: Comunidad, Identidad, Estabilidad. Dentro, la enorme sala de la planta baja se hallaba orientada hacia el Norte. Fría a pesar del verano que reinaba en el exterior y del calor tropical de la sala, una luz cruda se filtraba a través de las ventanas buscando ávidamente algún cuerpo amortajado o alguna figura pálida, producto de las disecciones académicas; sin encontrar más que el cristal, el níquel y la brillante porcelana de un laboratorio. Lo invernal respondía a lo invernal. Las batas de los trabajadores eran blancas, y éstos llevaban las manos enfundadas en guantes de goma de un color pálido, como de cadáver. La luz era helada, muerta, fantasmal. Sólo de los amarillos cilindros de los microscopios se lograba arrancar cierta calidad de vida, deslizándose a lo largo de los tubos y formando una dilatada procesión de trazos luminosos que seguían la larga perspectiva de las mesas de trabajo.\"\n",
    "pandasText = pd.DataFrame([texto],columns = ['Texto'], index = [1])\n",
    "texto1 = \"Dulzor, 5; Amargor, 1; Burbujas; 10\"\n",
    "texto2 = \"El encuestado opino que la bebida tenia un dulzor 5; asigno a amargor un 1 y a burbujas un 10\"\n",
    "pandasText1 = pd.DataFrame([texto1],columns = ['Texto'], index = [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1.- Eliminacion de stopwords y ruido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing stopwords: Stop words include the large number of prepositions, pronouns, conjunctions etc in sentences. These words need to be removed before we analyse the text, so that the frequently used words are mainly the words relevant to the context and not common words used in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista de stop words en espanol. Util para elminaras del texto original.\n",
    "stopWords = set(stopwords.words(\"spanish\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pasoPanda(texto):\n",
    "    output = pd.DataFrame([texto],columns = ['Texto'], index = [1])\n",
    "    return output\n",
    "\n",
    "def preProcesamiento(textoPandas,stopWords, deleteStopWords = 1, lemanizar= 0):\n",
    "    #Funcion que realiza el preProcesamiento del texto.\n",
    "    \n",
    "    #Convertir a Pandas.\n",
    "    text = textoPandas['Texto'][1]\n",
    "    #Pasar a minusculas.\n",
    "    text = text.lower()\n",
    "    #Eliminar comas y simbolos.\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    #Convertir a vector de palabras.\n",
    "    text = text.split()\n",
    "    #Eliminar stopWords\n",
    "    text = [word for word in text if not word in stopWords]\n",
    "    #Decidir si lemanizar o no\n",
    "    if lemanizar == 1:\n",
    "        lem = WordNetLemmatizer()\n",
    "        text = np.array([lem.lemmatize(word) for word in text])\n",
    "    elif lemanizar == 2:\n",
    "        stem = PorterStemmer()\n",
    "        text = np.array([stem.stem(word) for word in text])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar el texto preProcesado. Se entrega un vector con las palabras clave.\n",
    "text = preProcesamiento(pandasText,stopWords,lemanizar=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['edificio', 'gris', 'achaparrado', 'sólo', 'treinta', '4',\n",
       "       'plantas', 'encima', 'entrada', 'principal', 'palabras', 'centro',\n",
       "       'incubacion', 'condicionamiento', 'central', 'londres', 'escudo',\n",
       "       'divisa', 'mundial', 'comunidad', 'identidad', 'estabilidad',\n",
       "       'dentro', 'enorme', 'sala', 'planta', 'baja', 'hallaba',\n",
       "       'orientada', 'hacia', 'norte', 'fría', 'pesar', 'verano',\n",
       "       'reinaba', 'exterior', 'calor', 'tropical', 'sala', 'luz', 'cruda',\n",
       "       'filtraba', 'través', 'ventanas', 'buscando', 'ávidamente',\n",
       "       'algún', 'cuerpo', 'amortajado', 'alguna', 'figura', 'pálida',\n",
       "       'producto', 'disecciones', 'académicas', 'encontrar', 'cristal',\n",
       "       'níquel', 'brillante', 'porcelana', 'laboratorio', 'invernal',\n",
       "       'respondía', 'invernal', 'bata', 'trabajadores', 'blancas',\n",
       "       'éstos', 'llevaban', 'manos', 'enfundadas', 'guantes', 'goma',\n",
       "       'color', 'pálido', 'cadáver', 'luz', 'helada', 'muerta',\n",
       "       'fantasmal', 'sólo', 'amarillo', 'cilindros', 'microscopios',\n",
       "       'lograba', 'arrancar', 'cierta', 'calidad', 'vida', 'deslizándose',\n",
       "       'largo', 'tubos', 'formando', 'dilatada', 'procesión', 'trazos',\n",
       "       'luminosos', 'seguían', 'larga', 'perspectiva', 'mesa', 'trabajo'],\n",
       "      dtype='<U16')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringNumerico (word):\n",
    "    #Funcion que verifica si un string es numerico\n",
    "    try:\n",
    "        val = int(word)\n",
    "        output = True\n",
    "    except ValueError:\n",
    "        output = False\n",
    "    return output\n",
    "\n",
    "#Funcion que realiza la busqueda de la calificacion.\n",
    "def buscarValorAsociado(caracteristica, vectorTexto):\n",
    "    indiceCaracteristica = np.where(vectorTexto == caracteristica)\n",
    "    calificacion = int(vectorTexto[indiceCaracteristica[0]+1])\n",
    "    return calificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar el texto preProcesado. Se entrega un vector con las palabras clave.\n",
    "text1 = preProcesamiento(pandasText1,stopWords,lemanizar=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dulzor', '5', 'amargor', '1', 'burbujas', '10'], dtype='<U8')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buscarValorAsociado('amargor',text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = pasoPanda(audioPrueba)\n",
    "text2 = preProcesamiento(text2,stopWords,lemanizar=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dulzura', 'dulc', 'dulc', 'dulcísimo', 'dulc', 'dulc', 'dulc',\n",
       "       'dulc', 'amargo', 'amargo', 'amargo', 'amargo', 'amargo'],\n",
       "      dtype='<U9')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
